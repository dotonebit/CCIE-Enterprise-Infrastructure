IP was designed to provide best-effort service for delivery of data packets and to run across virtually any network transmission media and system platform.
Network traffic from business-critical and delay-sensitive applications must be serviced with priority and protected from other types of traffic.
This is the job of QoS.
Better performance from the network is achieved by managing bandwidth provisioning, delay, jitter (delay variation), and packet loss with QoS mechanisms.
Many QoS building blocks or features operate at different parts of a network to create an end-to-end QoS system.
Examples:
 - traffic is classified and assigned a priority when forwarded by access switches
 - different congestion management mechanisms for different types of traffic are used at the core


Converged Networks
------------------
Converged networks carry multiple types of traffic, such as voice, video, and data, which were traditionally transported on separate and dedicated networks.
Converged networks must balance the requirements for each different traffic types, which can compete for available resources.
Voice and some video traffic are not tolerant of delay, jitter, or packet loss, and excessive amounts of any of these will result in a poor experience for the end users. 
Data flows are typically more tolerant of delay, jitter, and packet loss but are very bursty in nature and will typically use as much bandwidth as possible.
The different traffic flows on a converged network will be in competition for network resources.
The critical, time-sensitive flows must be given priority in order to preserve the quality of this traffic.

Four major problems affect quality on converged networks:
- Bandwidth capacity:  Multiple traffic flows compete for a limited amount of bandwidth and may require more bandwidth than is available.
- Delay: Delay is the time that it takes for a packet to reach the receiving endpoint after being transmitted by the sender.
  There are variable delay components (processing and queueing delay) and fixed delay components (serialization and propagation delay).
- Jitter: Jitter is the variation in latency or end-to-end delay that is experienced between when a signal is sent and when it is received.
- Packet loss: Loss of packets is usually caused by congestion, faulty connectivity, or faulty network equipment.

Different techniques are employed to manage quality issues:
- increase the link capacity to accommodate the bandwidth requirements
- use a queuing technique to prioritize critical traffic or enabling a compression technique to reduce the number of bits that are transmitted for packets on the link
- a dejitter buffer can buffer packets and then play them out in a steady stream
  This process adds to the total delay of the packet that is being delivered as an audio or video stream but allows for a smooth delivery of the real-time traffic.
  If the amount of jitter that is experienced by the packet exceeds the dejitter buffer limits, the packet is dropped and the quality of the media stream is affected.
 

QoS Defined
-----------
The ability of the network to predictably provide business applications with the service required for those applications to be successfully used on the network.
QoS provides tools for managing network congestion, shaping network traffic, using links more efficiently, and setting traffic policies across the network.
QoS gives priority to some sessions over other sessions.
When queue buffers overflow, packets are dropped dterministically with minimal business impact.
QoS policies selectively delay or drop packets when contention arises.
QoS is not a substitute for bandwidth. 
If the network is congested, packets will be dropped. 
QoS allows the administrators control on how, when, and what traffic is dropped during congestion.

NOTE: Quality of Experience (QoE) measures end-user perception of the network performance. 
      QoE is not a technical metric; it is a subjective metric describing the end-user experience. 
      You deploy QoS features to maximize QoE for the end user.
      
      
QoS Policy
----------
A QoS policy is a definition of the QoS levels that are assigned across a network.
There are three basic steps involved in defining QoS policies for a network:
  1. Identify traffic and its requirements.
     Identifying network traffic can be accomplished by deploying classification tools on the network such as Network-Based Application Recognition (NBAR), 
     NetFlow, or packet sniffers, and by conducting interviews with the different departments of the enterprise to identify business-critical applications.
  2. Divide traffic into classes.
     It is recommended that data traffic be classified into no more than four groups.
     Mission-critical: Applications that are deemed to be the most significant for the success of the enterprise.
     Transactional and interactive: Typically client/server models that consist of user-initiated queries that are followed by server responses, 
     or traffic with strict user feedback requirements.
     Best-effort: All non-critical traffic that has not been assigned to a specific data queue will utilize this class.
     Scavenger: All data traffic that is used by non-business applications.
  3. Define QoS policies for each class.
     The following parameters must be defined for each traffic class:
       - minimum or maximum bandwidth
       - priority
       - congestion management technique

Example traffic classification:
  Voice: Absolute priority for VoIP traffic
  Mission-critical: Small set of locally defined applications that are critical to the business
  Transactional and interactive: Database access, transaction services, interactive traffic, and preferred data services
  Best-effort: Internet access and email
  Scavenger: Nonbusiness applications such as peer-to-peer file sharing, streaming audio or video sites, or gaming sites
  
NOTE: Priority values typically range from 0 for low-priority traffic to 7 for high-priority traffic. 
      These values can be carried in Layer 2 802.1Q frame headers as a class of service (CoS) value 
      or Layer 3 IP packets as IP Precedence or as part of Differentiated Services Code Point (DSCP) value.  


QoS Mechanisms
--------------
- a set of tools and techniques to manage network resources
- allow different types of traffic to contend inequitably for network resources

Several important mechanisms are used to implement a QoS policy in an IP network:
- Classification: all traffic is typically classified at the input interface of a QoS-aware device at the access layer and network edge
- Marking: Packets are marked based upon classification, metering, or both for identifying the required treatment, typically performed 
  as close to the network edge as possible
- Congestion management: Each interface must have a queuing mechanism to prioritize the transmission of packets based on the packet marking. 
  Congestion management is normally implemented on all output interfaces in a QoS-enabled network.
- Congestion avoidance: Specific packets are dropped early, based on marking, in order to avoid congestion on the network. 
  Congestion avoidance mechanisms are typically implemented on output interfaces wherever a high-speed link or set of links feeds into a lower-speed link.
- Policing and shaping: Traffic conditioning mechanisms police traffic by dropping misbehaving traffic to maintain network integrity or shape traffic to control bursts. 
  Policing mechanisms can be used at either input or output interfaces, while shaping mechanisms are only used on output interfaces.
- Link efficiency: Link efficiency mechanisms improve bandwidth efficiency or the serialization delay impact of low-speed links 
  through compression and link fragmentation and interleaving.
  
  
Classification and Marking
--------------------------
In any network in which networked applications require differentiated levels of service, traffic must be sorted into different classes upon which QoS is applied.
Classification allows network devices to identify traffic as belonging to a specific class with specific QoS requirements.
After network traffic is sorted, individual packets are marked (also called colored) so that the QoS features can be applied uniformly to those packets.
Classification is the identifying and splitting of traffic into different classes.
Traffic can be classified by various means.
Without classification, all packets are treated the same.
Using packet classification, you can partition network traffic into multiple priority levels or classes of service.
It is recommended that classification occur as close to the source of the traffic as possible.
The concept of trust is key for deploying QoS.
Switches and routers are generally set to not trust end devices and must specifically be configured to trust packets coming from an interface.
Marking, also known as coloring, marks each packet as a member of a network class.

CoS, Type of Service (ToS), DSCP, Class Selector, and Traffic Identifier (TID) are different terms to describe designated fields in a frame or packet header. 
How devices treat packets in your network depends on the field values.

Layer 3 packet marking with IP Precedence and DSCP is the most widely deployed marking option because Layer 3 packet markings have end-to-end significance. 
Layer 3 markings can also be easily translated to and from Layer 2 markings.


Policing and Shaping
--------------------

  
Source: ENCOR - Network Switching - Introducing QoS (Cisco U.)
 
